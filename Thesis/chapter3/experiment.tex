\section{Experimental Evaluation}\label{gw:sec:exp}
In this section, we present a comprehensive experimental evaluation 
of our solutions using several real-world information networks and 
various synthetic datasets. 
%Since the focus of this chapter is on query efficiency, we do not evaluate the efficiency of index updates. 
All experiments are conducted on an 
Amazon EC2 r3.2xlarge machine\footnote{http://aws.amazon.com/ec2/pricing/}, 
with an 8-core 2.5GHz CPU, 60GB memory and 320GB hard drive 
running with 64-bit Ubuntu 12.04. As the source code of EAGR is not
available, we implemented it and used it as a reference in our comparative
study.  
All algorithms are implemented in Java and run under JRE 1.6.

\begin{table}[h]
\caption{Large-scale real graphs.}
\label{tab:realdata}
\centering
\begin{tabular}{|l|l|l|l|}
\hline 
\rule[-1ex]{0pt}{2.5ex} Name & Type & Number of Vertexes & Number of Edges \\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} LiveJournal1 & undirected & 3,997,962 & 34,681,189 \\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} Pokec & directed & 1,632,803 & 30,622,564 \\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} Orkut & undirected & 3,072,441 & 117,185,083 \\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} DBLP & undirected & 317,080 & 1,049,866 \\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} YouTube & undirected & 1,134,890 & 2,987,624 \\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} Google & directed & 875,713 & 5,105,039 \\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} Amazon & undirected & 334,863 & 925,872 \\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} Stanford-web & directed & 281,903 &  2,312,497 \\ 
\hline 
\end{tabular}
\end{table}


\textbf{Datasets.} For real datasets, we use 8 information networks 
which are available at the Stanford \emph{SNAP}\footnote{http://snap.stanford.edu/snap/index.html}: 
LiveJournal1, Pokec, Orkut, DBLP, YouTube, Google, Amazon and Stanford-web. 
The detail description of these datasets is provided in 
Table~\ref{tab:realdata}. 

For synthetic datasets, we use two widely used graph data generators. 
We use the \emph{DAGGER} generator \cite{yildirim2013dagger} to generate 
all the synthetic DAGs and the SNAP graph data generator at the
Stanford SNAP website to generate non-DAG datasets. For each dataset, each vertex is associated with an integer attribute.

\textbf{Query.} In all the experiments, the window query is conducted 
by using the SUM() as the aggregate function over the integer attribute in each dataset. 

\begin{figure*}[t]
\centering
\begin{subfigure}{0.45\textwidth}
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/effectiveness/amazon_index_time.pdf}
  \caption{Index built on Amazon}
\end{subfigure}
\begin{subfigure}{0.45\textwidth}
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/effectiveness/stanford_index_time.pdf}
  \caption{Index built on Stanford-web}
\end{subfigure}

\begin{subfigure}{0.45\textwidth}
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/effectiveness/amazon_index_size.pdf}
  \caption{Index size on Amazon}
\end{subfigure}
\begin{subfigure}{0.45\textwidth}
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/effectiveness/stanford_index_size.pdf}
  \caption{Index size on Stanford-web}
\end{subfigure}
\caption{Index construction analysis for EMC and MC. (a) and (b) 
depict the index time for the Amazon and Stanford-web networks.
(c) and (d) show the index size for the Amazon and Stanford-web datasets.}
\label{fig:index_analysis_emc_mc}
\end{figure*}


\subsection{Comparison between MC and EMC}\label{sec:mc_vs_emc}
We first compare the effectiveness of the two DBIndex 
construction algorithms: MinHash Clustering (MC) and Estimated 
MinHash Clustering (EMC). We look at 
the index construction time, index size and query performance. 
All these experiments are conducted based on two real datasets: 
Amazon and Stanford-web. For both datasets, we run a series of k-hop queries.\footnote{For the Stanford-web graph, which is directed,
the k-hop windows are directed k-hop windows where $u \in W(k)$ if there is a directed path
of at most $k$ hops from vertex $v$ to vertex $u$.
} For queries with hop count larger than 1, 
EMC uses 1-hop information for the initial clustering. 

\textbf{Index Construction. } Figures~\ref{fig:index_analysis_emc_mc} 
(a) and (b) compare the index construction time between MC and EMC 
when we vary the windows from 1-hop to 4-hop for the Amazon and Stanford-web 
graphs respectively. To better understand the time differences, 
the construction time is split into two parts: 
the MinHash cost (EMC-hash or MC-hash) and the breadth-first-search traversal (to compute the $k$-hop window)  cost (EMC-bfs or MC-bfs). The results show the same trend 
for the two datasets. % We make several observations.
First, as the number of hops increases, the index construction time increases as well. 
This is expected as a larger hop count results in a larger window size 
and the BFS and the MinHash time increase correspondingly. 
Second, as the hop count increases, the difference between the
index construction time of EMC and that of MC widens. 
For instance, as shown in Figures~\ref{fig:index_analysis_emc_mc} (a) and (b), for the 4-hop window queries, compared to MC, 
EMC can save $62\%$ and $66\%$ construction time for the Amazon and Stanford-Web datasets respectively.
EMC benefits from both the low MinHash cost and low BFS cost. 
%From Figures~\ref{fig:index_analysis_emc_mc} (a) and (b), 
We can also see that the MinHash cost of MC increases as the number of hops 
increases, while that for EMC remains almost the same as the 1-hop case. 
This shows that the cost of MinHash becomes more significant for larger windows. 
Thus, using 1-hop clustering for larger hop counts reduces the MinHash cost 
in EMC. Similarly, as EMC saves on BFS cost for $k$-hop queries where $k > 1$, 
the BFS cost of EMC is much smaller than that of MC as well. 

\textbf{Index Size.} Figures~\ref{fig:index_analysis_emc_mc} (c) and (d) 
present the effect of hop counts on the index size for the Amazon and Stanford-web 
datasets respectively. The y-axis shows the index ratio which is the index size over the original graph size. 
The insights derived are: 
First, the index size is rather small compared to the original graph: it
varies from $3\%$ to $12\%$ of the original graph for the Amazon dataset 
and from $8\%$ to $22\%$ for the Stanford-web dataset. 
Second, the index size decreases as the number of hops increases. 
While this appears counter-intuitive initially, it is actually reasonable: a larger hop results in a bigger window, which leads
to more dense blocks. Third, the index ratio of EMC is slightly larger 
than that of MC for larger hop count. This indicates that MC can find more dense blocks 
than EMC to reduce the index size. Fourth, the index ratio on 
the Amazon dataset is much smaller than the ones on the Stanford-web dataset. 
This is because the Amazon dataset is undirected while the Stanford-web dataset
is directed. For the Stanford-web dataset, since we use directed k-hop windows, the window size is naturally smaller. 

\begin{figure}[h]
\centering
\begin{subfigure}{0.48\linewidth}
\centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/effectiveness/amazon_query_time.pdf}
  \caption{Amazon graph}
\end{subfigure}%
\begin{subfigure}{0.48\linewidth}
\centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/effectiveness/stanford_query_time.pdf}
  \caption{Stanford-web graph}
\end{subfigure}
\caption{Query performance comparison of MC and EMC.}
\label{fig:khop_effective_query_time}
\end{figure}

\textbf{Query Performance.}       
Figures~\ref{fig:khop_effective_query_time} (a) and (b)
present the query time of MC and EMC 
on the two datasets respectively 
as we vary the number of hops from 1 to 4.
To appreciate the benefits of an index-based scheme, we also implemented
a \emph{Non-indexed} algorithm which computes window aggregate by performing $k$-bounded breadth
first search for each vertex individually in run time.
In Figures~\ref{fig:khop_effective_query_time} (a) and (b),
the execution time shown on the y-axis is in log scale. The results show that the index-based 
schemes outperform the non-index approach by four orders of magnitude. 
For instance, for the 4-hop query over the Amazon graph, 
our algorithm is 13,000 times faster than the non-index approach. 
This confirms that it is necessary to have well-designed index support 
for efficient window query processing. By utilizing DBIndex, 
for these graphs with millions of edges, every aggregation query 
can be processed in just between 30ms to 100ms for the Amazon graph and 
between 60ms to 360ms for the Stanford-web graph. In addition, we can 
see that as the number of hops increases, the query time decreases. 
This is the case because a larger hop count eventually results in a larger
number of dense blocks where more (shared) computation can be salvaged. 
Furthermore, we can see that the query time of EMC is slightly longer 
than that of MC when the number of hops is large. This is expected as 
EMC does not cluster based on the complete window information; instead, it
uses only partial information derived from the 1-hop windows. 
However, the performance difference is quite small even for 4-hop queries: for
the Amazon dataset, the difference is only 20ms; and for the Stanford-web
graph, the difference is 35ms. 
For small number of hops, the time difference is even smaller. 
This performance penalty is acceptable as tens of milliseconds time 
difference will not affect user's experience.  As EMC is significantly more 
efficient than MC in index construction, EMC may still be a 
promising solution to many applications. As such, 
in the following sections, we adopt EMC for DBIndex in
our experimental evaluations.  
 

\subsection{Comparison between DBIndex and EAGR}

In this set of experiments, we compare DBIndex and 
EAGR \cite{mondal2014eagr} using both large-scale real 
and synthetic datasets. As described in~\cite{mondal2014eagr},
for each dataset, EAGR runs for 10 
iterations in the index construction.

\begin{figure}[h]
\centering
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/real_data/real_index_time_h1.pdf}
  \caption{1-hop index construction}
\end{subfigure} \begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/real_data/real_query_time_h1.pdf}
  \caption{1-hop query performance}
\end{subfigure}%
\caption{Comparison between DBIndex and EAGR  for 1-hop query.}
\label{fig:1-hop-real}
\end{figure}

\begin{figure}[h]
\centering
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/real_data/real_index_time_h2.pdf}
  \caption{2-hop index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/real_data/real_query_time_h2.pdf}
  \caption{2-hop query performance}
\end{subfigure}
\caption{Comparison between DBIndex and EAGR for 2-hop query.}
\label{fig:2-hop-real}
\end{figure}

\subsubsection{Real Datasets} 
We first study the index construction and 
query time performance of DBIndex and EAGR for 1-hop and 2-hop windows 
using 6 real datasets: DBLP, Youtube, Livejournal, Google, Pokec and Orkut. 
The results for 1-hop window and 2-hop window are presented
in Figures~\ref{fig:1-hop-real} and~\ref{fig:2-hop-real} 
respectively. 
As shown in Figures~\ref{fig:1-hop-real}(a) and~\ref{fig:2-hop-real}(a), both DBIndex and EAGR can build the index for all
the real datasets for the 1-hop but EAGR runs out of the memory for the 2-hop query on LiveJournal and Orkut datasets. This further confirms that EAGR incurs 
high memory usage as it needs to build the FP-Tree and 
maintain the vertex-window mapping information. We also observe that 
DBIndex is significantly faster than EAGR in index creation. 
We emphasize that the time is shown in logarithmic scale. 
For instance, for Orkut dataset, EAGR takes 4 hours to build the index 
while DBIndex only takes 33 minutes. 

Figure~\ref{fig:1-hop-real} (b) and Figure~\ref{fig:2-hop-real} (b) 
show the query performance for 1-hop and 2-hop queries respectively. 
The results indicate that the query performance is comparable. 
For most of the datasets, DBIndex is faster than EAGR.
In some datasets (e.g. Orkut and Pokec), DBIndex performs 30\% faster than the EAGR. 
We see that, for the 1-hop query on 
Youtube and LiveJournal datasets and the 2-hop query 
on Youtube dataset, DBIndex is slightly slower than EAGR. We observe 
that these datasets are very sparse graphs where the intersections among windows are naturally small. For very sparse graphs, 
both DBIndex and EAGR are unable to find much computation sharing. In this case, the performance of DBIndex and EAGR is very close. For instance, in the worst case of Livejournal, DBIndex is 9\% slower than EAGR where the actual time difference remains tens of milliseconds.    
%
Another insight is that as expected, compared to Figure~\ref{fig:1-hop-real} (b), 
the 2-hop query runs faster for both algorithms. This is because there is more computation sharing for the 2-hop query. 

In summary, 
DBIndex takes much shorter time to build but offers comparable, if not much faster, query 
performance than EAGR.


\subsubsection{Synthetic Datasets}
To study the scalability of DBIndex under large-scale graphs, 
we generated synthetic datasets using the SNAP generator. 

% streching from 2M vertices to 10M vertices. To see the scalability of our index, we perform extensive tests from both degree and vertex angle.  All data are generated from SNAP\footnote{http://snap.stanford.edu/snap/download.html} graph generator program. We use EAGR as a comparison method. We reported our findings below:

\textbf{Impact of Vertexes.} First, we study how the performance 
changes when we fix the degree\footnote{Degree means average degree of the graph. The generated graph is of Erdos-Renyi model } at 10 and vary the number of vertexes from 
2M to 10M. Figures~\ref{fig:khop_d10_h1} (a) and (b) show the execution time for index construction and query performance respectively. 
From the results, we can see that DBIndex outperforms EAGR in
both index construction and query performance. For the graph with 10M vertexes and 100M edges, the DBIndex query time is less than 450 milliseconds. 
%The increment of DBIndex query with respect to vertex is also steady. 
Moreover, when the number of vertexes changes from 2M to 10M, 
the query performance only increases 3 times. This shows that
DBIndex is not only scalable, but offers acceptable performance. Figures~\ref{fig:khop_d10_h1} (c) and (d) show the
performance of DBIndex in processing the 2-hop query. We notice that EAGR fails to run due to the high memory requirement. For instance, when vertex equals to 2M, the 2-hop query generates 90GB intermediate data, which exceeds the available memory
.

\begin{figure}[t]
\centering
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/d10h1_index.pdf}
  \caption{1-hop index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/d10h1_query.pdf}
  \caption{1-hop query performance}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/d10h2_index.pdf}
  \caption{2-hop index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/d10h2_query.pdf}
  \caption{2-hop query performance}
\end{subfigure}
\caption{Impact of number of vertexes.}
\label{fig:khop_d10_h1}
\end{figure}

\begin{figure}[t]
\centering
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/varyd_index_2M.pdf}
  \caption{1-hop index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/varyd_query_2M.pdf}
  \caption{1-hop query performance}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/varyd_index_2M_h2.pdf}
  \caption{2-hop index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/varyd_query_2M_h2.pdf}
  \caption{2-hop query performance}
\end{subfigure}
\caption{Impact of degree in sparse graphs with 2M vertexes.}
\label{fig:khop_v2m}
\end{figure}

\textbf{Impact of Sparse Graphs.} Our proposed DBIndex is effective when there is significant overlap between windows of neighboring nodes. As such, it is interesting to study how it performs for sparse graph where the vertexes may not share many common neighbors. In these experiments, 
we study the impact of degree when the graph is relatively sparse.
We fix the number vertexes of 2M and vary the vertex degree from 5 to 30. 
Figures~\ref{fig:khop_v2m} (a) and (c) present the results 
on index construction for the 1-hop and the 2-hop queries respectively. 
For the 1-hop query, as degree increases, the time for index
construction also increases. 
However, the index creation time of DBIndex increases much 
slower than EAGR. This is because EAGR incurs relatively more 
overhead to handle multiple FP-Tree creation and reconstruction. 
For the 2-hop query, EAGR again fails to run due to the memory limitation. %This is because even for a very sparse graph (i.e., degree 5), the initial vertex-mapping can be as large 
%as 90GB in a linked list representation, which exceeds the available memory. 
%Note that the size becomes even larger when it is stored in the matrix form.
Therefore, we only show the results of DBIndex. 
In Figure~\ref{fig:khop_v2m} (c), the index construction time of DBIndex increases as the 
degree increases. This is expected as a bigger degree  
increases the overhead of graph traversal time to collect the window. 


Figures~\ref{fig:khop_v2m} (b) and (d)
show the results on query time 
for 1-hop and 2-hop queries respectively. 
We observe a similar pattern for the index construction time:
for the 1-hop query, the query time increases with increasing degree
but at a much slower rate than EAGR; For the 2-hop query, we observe in Figure~\ref{fig:khop_v2m} (d) that the
query performance of DBIndex hovers around 100ms, which is much 
smaller than that of the 1-hop query performance. 
This is because there are more dense blocks in the 2-hop case, 
in which case the query time can be faster compared to the 1-hop case. 

\textbf{Impact of Dense Graphs.} We study the 
impact of degree over very dense graphs with 200k vertexes 
when the degree changes from 80 to 200. 
Figures~\ref{fig:khop_v200k} (a) and (c) show
the execution time for index construction 
for 1-hop and 2-hop queries respectively. From the results, 
we can see that DBIndex also performs well on dense graphs. 
As the degree increases, EAGR's performance degrades much faster than DBIndex. For the 2-hop query,
as shown in Figures~\ref{fig:khop_v200k} (b) and (d), EAGR is only able to work on 
the dataset with degree 80 due to the memory issue. 
Even though the number of vertexes is relatively small (only 200k), 
the number of edges is very large when the degree becomes big 
(e.g. 40M edges with degree of 200). 
%
Figures~\ref{fig:khop_v200k} 
(b) and (d) show the results on query performance 
for the 1-hop and the 2-hop queries respectively. 
The results are consistent with that for sparse graphs: DBIndex is superior over EAGR. 

In summary, the insight we obtained is that the scalability of EAGR 
is highly limited by its large usage of memory.
%: the graph size and the number of hops. 
DBIndex achieves better scalability as it does not need to 
create a large amount of intermediate data in memory. 

\begin{figure}[h]
\centering
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/varyd_index_200k.pdf}
  \caption{1-hop index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/varyd_query_200k.pdf}
  \caption{1-hop query performance}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/varyd_index_200k_h2.pdf}
  \caption{2-hop index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/khopeffect/scalability/varyd_query_200k_h2.pdf}
  \caption{2-hop query performance }
\end{subfigure}
\caption{Impact of degree in dense graphs with 200K vertexes.}
\label{fig:khop_v200k}
\end{figure}

\subsection{Evaluation of I-Index}
In this set of experiments, we evaluate I-Index. 
All the datasets are generated from the DAGGER generator.   

\begin{figure}[h]
\centering
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/topoeffect/comp/top_index_time_v30k.pdf}
  \caption{Index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/topoeffect/comp/top_query_time_v30k.pdf}
  \caption{Query performance}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/topoeffect/comp/top_index_time_v60k.pdf}
  \caption{Index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/topoeffect/comp/top_query_time_v60k.pdf}
  \caption{Query performance}
\end{subfigure}
\caption{Impact of degree with the fixed number of vertexes.}
\label{fig:pi_effect}
\end{figure}

\textbf{Impact of Degree.} We evaluate the impact of degree when we fix the number of vertex as 30k and 60k.  
We compare \emph{DBIndex} with I-Index. 
In the query results, we also implement one non-index algorithm 
which dynamically calculates the window and then performs the aggregation. 
For index construction time, as shown in Figures~\ref{fig:pi_effect} (a) and (c), as the 
index size increases, both the index construction time of 
DBIndex and I-Index increase. However I-Index is more efficient than 
DBIndex, this is benefit from the inheritance optimization.  We observe that the 
index construction time is almost the same as the non-indexed query time. In other words, 
we can use one query time to create the index which is able to subsequently provide much faster query processing. 
In terms of query performance, shown in Figures~\ref{fig:pi_effect} (b) and (d), the non-index approach is in average 20 times slower than 
the indexed schemes. Meanwhile, I-Index outperforms DBIndex by 20\% to 30\%, which confirms the superiority of I-Index.
%The results clearly show that I-Index outperforms DBIndex for topological 
%window in both index construction and query performance.
%Since I-Index is superior, in the following experiments, we only present the results for I-Index. 

\textbf{Impact of Number of Vertexes.} Then, we study 
the effect of graph size by varying the number of vertexes from 50k to 350K.
%the performance of I-Index 
% is affected when we fix the degree and vary the number of Vertexes from 50k to 350K. 
Figures~\ref{fig:pi_effect2} (a) and (c) show the index construction time when we fix the degree to 
10 and 20 respectively. From the results, we see that the construction time increases as the number of vertexes increases and the construction time of a high degree graph is longer than that for low the degree graph. Figures~\ref{fig:pi_effect2} (b) and (d) show the query time when we fix the degree to 10 and 20 respectively. 
As shown, the degree affects the query processing time: when the degree increases, the query time increases as well. We also observe that the query time is increasing linearly when the number of vertexes increases. This shows that I-Index has good scalability.
  
\begin{figure}[t]
\centering
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/topoeffect/comp/top_scale_index_d10.pdf}
  \caption{Index construction }
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/topoeffect/comp/top_scale_query_d10.pdf}
  \caption{Query performance}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/topoeffect/comp/top_scale_index_d20.pdf}
  \caption{Index construction}
\end{subfigure}
\begin{subfigure}{0.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{chapter3/exp/topoeffect/comp/top_scale_query_d20.pdf}
  \caption{Query performance}
\end{subfigure}
\caption{Impact of the number of vertexes with a fixed degree. (a) and (b) 
are the results for the graphs with degree 10; (c) and (d) 
are the graphs with degree 20. }
\label{fig:pi_effect2}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{chapter3/exp/topoeffect/comp/top_scale_index_size.pdf}
\caption{Index ratio of I-Index.}
\label{fig:top-index-size}
\end{figure}


\textbf{Index Size.} Figure~\ref{fig:top-index-size} presents
the index size ratio (i.e. size of index divided by the size of original graph) under different degrees from 3 to 20. 
There are four different sizes of data used with 100k, 150k, 200k and 300k vertexes.  
For every vertex setting, the index size maintains the same trend in various degrees. The index size is linear to the input graph size. 
As a graph gets denser, the difference field of the I-Index
effectively shrinks. Thus, the index size in turn becomes smaller, which explains the bends in the figure.




